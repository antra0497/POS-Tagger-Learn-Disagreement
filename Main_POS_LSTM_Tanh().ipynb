{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required libraries"
      ],
      "metadata": {
        "id": "nJFPfo3V821-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7YyUbWTIatX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb28987-5230-45c1-e37e-645885424e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import csv\n",
        "import torch.utils.data as data_utils\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "from scipy.special import softmax\n",
        "\n",
        "from nltk import pos_tag\n",
        "import nltk\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Importing and Data Preparation"
      ],
      "metadata": {
        "id": "vi01Lj6g9IWl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwgFgYLoKXWH"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/MscThesis/public_data_PP/gimpel_pos'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Reading in the data**"
      ],
      "metadata": {
        "id": "s5hM7B9Z9lkV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRpWocMXKXdc"
      },
      "outputs": [],
      "source": [
        "def read_csv_data(path):\n",
        "  '''\n",
        "  User define function to read the .csv file from the given path\n",
        "  '''\n",
        "  data = []\n",
        "  with open(path, 'r') as f:\n",
        "    tsvreader = csv.reader(f, delimiter=\"\\t\")\n",
        "    for line in tsvreader:\n",
        "      data.append(line)\n",
        "    # to remove the header\n",
        "  return data[1:]\n",
        "\n",
        "\n",
        "def readbin(f_in):\n",
        "  '''\n",
        "  User define function to read the .bin file from the given path\n",
        "  '''\n",
        "  inp = open(f_in, \"rb\")\n",
        "  out = pickle.load(inp)\n",
        "  inp.close()\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GU_seH2KXgW"
      },
      "outputs": [],
      "source": [
        "# prepared word embeddings for the model.\n",
        "word_emb_matrix = DATA_PATH + '/embeddings/word_emb_matrix.bin'\n",
        "word_emb = readbin(word_emb_matrix)\n",
        "\n",
        "# prepared character embeddings for the model\n",
        "char_emb_matrix = DATA_PATH + '/embeddings/char_emb_matrix.bin'\n",
        "char_emb = readbin(char_emb_matrix)\n",
        "\n",
        "# the train and dev data from csv\n",
        "train_path = DATA_PATH + '/input_data/train_data.tsv'\n",
        "train_data = read_csv_data(train_path)\n",
        "\n",
        "dev_path = DATA_PATH + '/input_data/dev_data.tsv'\n",
        "dev_data = read_csv_data(dev_path)\n",
        "\n",
        "# the indices of the words in a sentence, saved as arrays. Hint:Helps you know where each sentence ends\n",
        "train_iis_path = DATA_PATH + '/input_data/word_iis_trn.npy'\n",
        "dev_iis_path = DATA_PATH + '/input_data/word_iis_dev.npy'\n",
        "\n",
        "word_iis_trn = np.load(train_iis_path)\n",
        "word_iis_dev = np.load(dev_iis_path)\n",
        "\n",
        "# the padded sentences (maximum of 40 words per sentence). Two words in the same sentence will have the same word_pad. The numbers\n",
        "# indicate the idx of the word in the word embedding dictionary.\n",
        "train_wordpad_path = DATA_PATH + '/input_data/word_pad_trn.npy'\n",
        "dev_wordpad_path = DATA_PATH + '/input_data/word_pad_dev.npy'\n",
        "\n",
        "word_pad_trn = np.load(train_wordpad_path)\n",
        "word_pad_dev = np.load(dev_wordpad_path)\n",
        "\n",
        "# the character padding\n",
        "train_charpad_path = DATA_PATH + '/input_data/char_pad_trn.npy'\n",
        "dev_charpad_path = DATA_PATH + '/input_data/char_pad_dev.npy'\n",
        "\n",
        "char_pad_trn = np.load(train_charpad_path)\n",
        "char_pad_dev = np.load(dev_charpad_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Getting the training labels**"
      ],
      "metadata": {
        "id": "yRkC_UV5-UDK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctDotC_mKXl9"
      },
      "outputs": [],
      "source": [
        "def get_soft(string_format):\n",
        "    annotator_dict = {ann_idx:labels_dict[annotation] for ann_idx, annotation in enumerate(string_format.split(',')) if annotation != \"\"}\n",
        "    ann_labs = list(annotator_dict.values())\n",
        "    distr = [ann_labs.count(l) for l in range(len(labels_dict))]\n",
        "    return distr, softmax(distr).tolist()\n",
        "\n",
        "labels_dict = {'ADJ': 0, 'ADP': 1, 'ADV': 2, 'CCONJ': 3, 'DET': 4,'NOUN': 5, 'NUM': 6, 'PART': 8,'PRON': 7,'PUNCT': 9,'VERB': 10, 'X': 11}\n",
        "\n",
        "\n",
        "train_softs = []\n",
        "train_distr = []\n",
        "for line in train_data:\n",
        "    if line:\n",
        "        distr, soft = get_soft(line[-1])\n",
        "        train_softs.append(soft)\n",
        "        train_distr.append(distr)\n",
        "\n",
        "#print((train_softs[5:], train_distr[5:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  **Training Parameters** "
      ],
      "metadata": {
        "id": "oAhmoMVLAr4-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDSr9m-rKXjV"
      },
      "outputs": [],
      "source": [
        "lstm_size = 128\n",
        "attn_size = 512\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "batsize = 1000\n",
        "sizeout_rate = 0.8\n",
        "\n",
        "word_emb_size = 300\n",
        "char_emb_size = 64\n",
        "\n",
        "word_padsize = word_pad_trn.shape[1]\n",
        "char_padsize = char_pad_trn.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Functions**"
      ],
      "metadata": {
        "id": "7k9iCO7KBF3P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGSAKw5bKXod"
      },
      "outputs": [],
      "source": [
        "#Embedding lookup used for word and character embeddings\n",
        "def lookup_embeddings(embedding_lookup, index_matrix):\n",
        "    flattened_indices = torch.flatten(index_matrix)\n",
        "    selected = torch.index_select(embedding_lookup, 0, flattened_indices)\n",
        "    return selected.reshape(index_matrix.shape[0], index_matrix.shape[1], embedding_lookup.shape[-1])\n",
        "\n",
        "# tensorizing the data\n",
        "def to_numpy(torch_tensor):\n",
        "    return torch_tensor.cpu().clone().detach().numpy()\n",
        "\n",
        "# to check GPU availability\n",
        "def to_cuda(x):\n",
        "    \"\"\" GPU-enable a tensor \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return x\n",
        "\n",
        "#Creating Tensor for dataloder\n",
        "def create_dataset(word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, has_labels=False, y_hot_trn_bat=None, y_soft_trn_bat=None):\n",
        "    word_pad_trn_bat, word_iis_trn_bat = torch.from_numpy(word_pad_trn_bat).long().to(device), torch.from_numpy(word_iis_trn_bat).long().to(device)\n",
        "    char_pad_trn_bat = torch.from_numpy(char_pad_trn_bat).long().to(device)\n",
        "    if has_labels:\n",
        "        y_hot_trn_bat = torch.from_numpy(y_hot_trn_bat).float().to(device)\n",
        "        y_soft_trn_bat = torch.from_numpy(y_soft_trn_bat).float().to(device)\n",
        "    return word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, y_hot_trn_bat, y_soft_trn_bat\n",
        "\n",
        "# to initialize to the optimizer\n",
        "def backprop_hot(optimizer, loss):\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return\n",
        "\n",
        "# to get predection from the model\n",
        "def get_predictions(model, eval_loader):\n",
        "    hard_preds = []\n",
        "    soft_preds = []\n",
        "    model.eval()\n",
        "    for wwordpad_bat, wwordiis_bat, ccharpad_bat in eval_loader:\n",
        "        one_hot_pred, _ = model(wwordpad_bat, wwordiis_bat, ccharpad_bat, None, None)\n",
        "        one_hot_pred = one_hot_pred.detach().cpu().numpy()\n",
        "        hard_preds.extend(np.argmax(one_hot_pred, 1))\n",
        "        soft_preds.extend(one_hot_pred)\n",
        "    return hard_preds, soft_preds\n",
        "\n",
        "# to calculate each epoch time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating Functions**"
      ],
      "metadata": {
        "id": "MsB1id9qBMmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To calculate the cross entropy for soft evaluation\n",
        "def cross_entropy_metric(targets, predictions, epsilon=1e-12):\n",
        "    \"\"\"\n",
        "    Computes cross entropy between targets and predictions.\n",
        "    Input: predictions (N, k) ndarray\n",
        "           targets (N, k) ndarray\n",
        "    Returns: scalar\n",
        "    https://stackoverflow.com/questions/47377222/what-is-the-problem-with-my-implementation-of-the-cross-entropy-function\n",
        "    \"\"\"\n",
        "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
        "    N = predictions.shape[0]\n",
        "    ce = -np.sum(targets*np.log(predictions))/N\n",
        "    return ce\n",
        "\n",
        "# To calculate F1- scores given actuall and predictions for hard evaluation\n",
        "def f1_metric(solution, prediction, num_classes=2):\n",
        "    matches, gold, system = {}, {}, {}\n",
        "    for i in range(num_classes):\n",
        "        matches[i] = 0\n",
        "        system[i] = 0\n",
        "        gold[i] = 0\n",
        "\n",
        "    for g, p in zip(solution, prediction):\n",
        "        if p == g:\n",
        "            matches[p] += 1\n",
        "\n",
        "        gold[g] += 1\n",
        "        system[p] += 1\n",
        "\n",
        "    recall = {}\n",
        "    precision = {}\n",
        "    f1 = {}\n",
        "    for i in range(num_classes):\n",
        "        recall[i] = 1.0 * matches[i] / gold[i] if matches[i] != 0 else 0\n",
        "        precision[i] = 1.0 * matches[i] / system[i] if matches[i] !=0 else 0\n",
        "        f1[i] =  (2 * (precision[i] * recall[i])/(precision[i] + recall[i])) if (precision[i] + recall[i]) > 0 else 0\n",
        "\n",
        "    support = np.array([gold[i] for i in range(num_classes)])\n",
        "\n",
        "    average_recall = np.average([recall[i] for i in range(num_classes)], weights=support)\n",
        "    average_precision = np.average([precision[i] for i in range(num_classes)], weights=support)\n",
        "    average_f1 = np.average([f1[i] for i in range(num_classes)], weights=support)\n",
        "    return average_f1, average_recall, average_precision\n",
        "\n",
        "# to load the jsonaline files\n",
        "def load_dictionary(filepath):\n",
        "    with open(filepath, 'r') as f:\n",
        "        dictionary = json.load(f)\n",
        "    return dictionary\n",
        "\n",
        "\n",
        "def get_hard_score(reference_path, submission_path, num_classes):\n",
        "\n",
        "    # submissions are in a dictionary format\n",
        "    reference_dictionary = load_dictionary(reference_path)\n",
        "    submission_dictionary = load_dictionary(submission_path)\n",
        "\n",
        "    # getting the submission vectors\n",
        "    golds = []\n",
        "    predictions = []\n",
        "    for document, doc_contents in reference_dictionary.items():      \n",
        "        sub = submission_dictionary[document]\n",
        "        for item_id, contents in doc_contents.items():\n",
        "            golds.append(contents['gold'])\n",
        "            predictions.append(sub[item_id]['gold'])\n",
        "\n",
        "    #print('Dev reference gold: ',golds)\n",
        "    #print('Dev result gold:', predictions)\n",
        "\n",
        "    f1, recall, precision = f1_metric(np.array(golds), np.array(predictions), num_classes)\n",
        "\n",
        "    return f1, recall, precision\n",
        "\n",
        "\n",
        "def get_soft_score(reference_path, submission_path):\n",
        "\n",
        "    # submissions are in a dictionary format\n",
        "    reference_dictionary = load_dictionary(reference_path)\n",
        "    submission_dictionary = load_dictionary(submission_path)\n",
        "\n",
        "    # getting the submission vectors\n",
        "    softs = []\n",
        "    predictions = []\n",
        "    for document, doc_contents in reference_dictionary.items():\n",
        "        sub = submission_dictionary[document]\n",
        "        for item_id, contents in doc_contents.items():\n",
        "            softs.append(contents['soft'])\n",
        "            predictions.append(sub[item_id]['soft'])\n",
        "    # evaluating using cross_entropy\n",
        "    score = cross_entropy_metric(np.array(softs), np.array(predictions))\n",
        "    return score"
      ],
      "metadata": {
        "id": "ujq8w14pLOpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting, Tensorizing and Batching the Data**"
      ],
      "metadata": {
        "id": "d9GmT73DBaF4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKdX4O4dKXrG"
      },
      "outputs": [],
      "source": [
        "train_softs = np.array(train_softs)\n",
        "train_softs.shape\n",
        "train_mv = np.argmax(train_softs, 1)\n",
        "\n",
        "#Creating Dev Dataloader\n",
        "word_pad_dev_tens, word_iis_dev_tens, char_pad_dev_tens, hot_dev_tens, soft_dev_tens = create_dataset(word_pad_dev, word_iis_dev, char_pad_dev)\n",
        "dev = data_utils.TensorDataset(word_pad_dev_tens, word_iis_dev_tens, char_pad_dev_tens)\n",
        "dev_loader = data_utils.DataLoader(dev, batch_size=batsize, shuffle=False)\n",
        "\n",
        "#Creating Train Dataloader\n",
        "word_pad_trn_tens, word_iis_trn_tens, char_pad_trn_ten, hot_trn_tens, soft_trn_tens = create_dataset(word_pad_trn, word_iis_trn, char_pad_trn, True, train_mv, train_softs)\n",
        "train = data_utils.TensorDataset(word_pad_trn_tens, word_iis_trn_tens, char_pad_trn_ten, hot_trn_tens, soft_trn_tens)\n",
        "train_loader = data_utils.DataLoader(train, batch_size=batsize, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model**"
      ],
      "metadata": {
        "id": "QpeRXYzcBdhD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVv-O7OQKXtm"
      },
      "outputs": [],
      "source": [
        "#Defining the Word Encoder\n",
        "class Word_Encoder(torch.nn.Module):\n",
        "    def __init__(self, lstm_size, embedding_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bilstm = torch.nn.LSTM(embedding_size, lstm_size, bidirectional=True, batch_first=True)\n",
        "        self.dropout = torch.nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, wword_pad, col_indices):\n",
        "        embedded_words = lookup_embeddings(word_embedding_lookup, wword_pad)\n",
        "        rnn_context, _ = self.bilstm(embedded_words)\n",
        "        rnn_sequence = torch.stack([torch.index_select(seq, 0, i) for seq, i in zip(rnn_context, col_indices)], 0)\n",
        "        rnn_sequence = self.dropout(rnn_sequence)\n",
        "        return rnn_sequence, rnn_context\n",
        "\n",
        "#Defining the Character Encoder\n",
        "class Char_Encoder(torch.nn.Module):\n",
        "    def __init__(self, lstm_size, embedding_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bilstm = torch.nn.LSTM(embedding_size, lstm_size, bidirectional=True, batch_first=True)\n",
        "        self.dropout = torch.nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, cchar_pad):\n",
        "        embedded_chars = lookup_embeddings(char_embedding_lookup, cchar_pad)\n",
        "        rnn_sequence, _ = self.bilstm(embedded_chars)\n",
        "        rnn_sequence = self.dropout(rnn_sequence[:,1])\n",
        "        reshaped = torch.reshape(rnn_sequence, [-1, 1, rnn_sequence.shape[1]])\n",
        "        return reshaped\n",
        "\n",
        "#Defining a seperate Attention\n",
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self, attn_emb_dim, attn_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn_nn = torch.nn.Sequential(\n",
        "                    torch.nn.Linear(attn_emb_dim, attn_size),\n",
        "                    torch.nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.u_omega = torch.nn.Parameter(torch.randn([attn_size]))\n",
        "\n",
        "    def forward(self, attn_in, s):\n",
        "        v = self.attn_nn(attn_in)\n",
        "        vu = torch.matmul(v.squeeze(1), self.u_omega)\n",
        "        alphas = torch.nn.functional.softmax(vu, 0)\n",
        "        final = torch.sum(attn_in * alphas.unsqueeze(-1), 1)\n",
        "        return final\n",
        "\n",
        "# Defining the finale RNN architecture\n",
        "class RNN_all(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.word_encoder = Word_Encoder(lstm_size, word_emb_size)\n",
        "        self.char_encoder = Char_Encoder(lstm_size, char_emb_size)\n",
        "\n",
        "        self.char_attention = Attention(lstm_size*2, attn_size)\n",
        "        self.word_attention = Attention(lstm_size*2, attn_size)\n",
        "\n",
        "        concat_size = lstm_size*4\n",
        "        hidden1 = int(lstm_size*4*sizeout_rate)\n",
        "        out_final = int(hidden1*sizeout_rate)\n",
        "        self.fulcon = torch.nn.Sequential(\n",
        "                    torch.nn.Linear(concat_size, hidden1),\n",
        "                    torch.nn.Linear(hidden1, out_final))\n",
        "\n",
        "        self.output_hot = torch.nn.Linear(out_final, hotsize)\n",
        "    \n",
        "    def forward(self, wword_pad, wword_iis, cchar_pad, one_hot_labels, soft_labels, eval=True):\n",
        "        word_sequence, word_context = self.word_encoder(wword_pad, wword_iis)\n",
        "        word_attn= self.word_attention(word_sequence, 'word')\n",
        "\n",
        "        char_sequence = self.char_encoder(cchar_pad)\n",
        "        char_attn = self.char_attention(char_sequence, 'char')\n",
        "\n",
        "        concat_attn = torch.cat([word_attn, char_attn], 1)\n",
        "        ful = self.fulcon(concat_attn)\n",
        "\n",
        "        pred_hot = self.output_hot(ful)  \n",
        "        softmax_scores = torch.nn.functional.softmax(pred_hot, 1) + 1e-43\n",
        "        if eval:\n",
        "            return softmax_scores, None\n",
        "        else:\n",
        "            soft_labels = soft_labels + 1e-43\n",
        "            softmax_scores = torch.nn.functional.softmax(pred_hot, 1) + 1e-4\n",
        "            cross_entropy = torch.mul(soft_labels, softmax_scores.log())\n",
        "            loss  = -torch.sum(cross_entropy)\n",
        "            return softmax_scores, loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Training"
      ],
      "metadata": {
        "id": "U_p83VmqBuxx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFzg3I6VKXwF",
        "outputId": "a0f4b2df-7f41-42fe-9175-e888f47f698a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning the Training\n",
            "\n",
            "Experiment 0 #######################\n",
            "Epoch: 01 | Epoch Time: 0m 2s\n",
            "Training Loss: 2075.7429809570312 | Training Acc: 0.29721149802207947\n",
            "------------------------------------------------------------\n",
            "Epoch: 02 | Epoch Time: 0m 2s\n",
            "Training Loss: 1611.9846327039932 | Training Acc: 0.5129712820053101\n",
            "------------------------------------------------------------\n",
            "Epoch: 03 | Epoch Time: 0m 1s\n",
            "Training Loss: 1416.1907721625435 | Training Acc: 0.6350609660148621\n",
            "------------------------------------------------------------\n",
            "Epoch: 04 | Epoch Time: 0m 1s\n",
            "Training Loss: 1294.696017795139 | Training Acc: 0.7100394368171692\n",
            "------------------------------------------------------------\n",
            "Epoch: 05 | Epoch Time: 0m 1s\n",
            "Training Loss: 1203.9942186143662 | Training Acc: 0.7553836107254028\n",
            "------------------------------------------------------------\n",
            "Epoch: 06 | Epoch Time: 0m 1s\n",
            "Training Loss: 1138.1594136555989 | Training Acc: 0.788641631603241\n",
            "------------------------------------------------------------\n",
            "Epoch: 07 | Epoch Time: 0m 1s\n",
            "Training Loss: 1084.8359375 | Training Acc: 0.820817232131958\n",
            "------------------------------------------------------------\n",
            "Epoch: 08 | Epoch Time: 0m 1s\n",
            "Training Loss: 1048.2578769259983 | Training Acc: 0.8361756801605225\n",
            "------------------------------------------------------------\n",
            "Epoch: 09 | Epoch Time: 0m 1s\n",
            "Training Loss: 1020.6796196831597 | Training Acc: 0.8500896692276001\n",
            "------------------------------------------------------------\n",
            "Epoch: 10 | Epoch Time: 0m 1s\n",
            "Training Loss: 996.8111911349827 | Training Acc: 0.8630322813987732\n",
            "------------------------------------------------------------\n",
            "Epoch: 11 | Epoch Time: 0m 1s\n",
            "Training Loss: 980.454345703125 | Training Acc: 0.8700823783874512\n",
            "------------------------------------------------------------\n",
            "Epoch: 12 | Epoch Time: 0m 1s\n",
            "Training Loss: 966.7266438802084 | Training Acc: 0.878677487373352\n",
            "------------------------------------------------------------\n",
            "Epoch: 13 | Epoch Time: 0m 1s\n",
            "Training Loss: 955.4120246039497 | Training Acc: 0.884390652179718\n",
            "------------------------------------------------------------\n",
            "Epoch: 14 | Epoch Time: 0m 1s\n",
            "Training Loss: 944.7471245659722 | Training Acc: 0.8954336643218994\n",
            "------------------------------------------------------------\n",
            "Epoch: 15 | Epoch Time: 0m 1s\n",
            "Training Loss: 934.3678317599827 | Training Acc: 0.8993834257125854\n",
            "------------------------------------------------------------\n",
            "Epoch: 16 | Epoch Time: 0m 1s\n",
            "Training Loss: 928.3805135091146 | Training Acc: 0.9007382988929749\n",
            "------------------------------------------------------------\n",
            "Epoch: 17 | Epoch Time: 0m 1s\n",
            "Training Loss: 919.8096076117622 | Training Acc: 0.9096558690071106\n",
            "------------------------------------------------------------\n",
            "Epoch: 18 | Epoch Time: 0m 1s\n",
            "Training Loss: 913.7166171603733 | Training Acc: 0.9137311577796936\n",
            "------------------------------------------------------------\n",
            "Epoch: 19 | Epoch Time: 0m 1s\n",
            "Training Loss: 907.2002597384983 | Training Acc: 0.9175733923912048\n",
            "------------------------------------------------------------\n",
            "Epoch: 20 | Epoch Time: 0m 1s\n",
            "Training Loss: 903.3610297309028 | Training Acc: 0.9167921543121338\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.functional import cross_entropy\n",
        "\"\"\"**Training using the soft labels**\"\"\"\n",
        "\n",
        "hotsize = 12\n",
        "assert len(train_softs[0]) == hotsize\n",
        "\n",
        "word_embedding_lookup = torch.from_numpy(word_emb).float().to(device)\n",
        "char_embedding_lookup = torch.from_numpy(char_emb).float().to(device)\n",
        "\n",
        "print('Beginning the Training')\n",
        "NUM_EXPERIMENTS = 1\n",
        "\n",
        "accs = [] #for training accuracy\n",
        "train_losses=[] # for training loss\n",
        "\n",
        "dev_accs = []\n",
        "dev_prfs = []\n",
        "\n",
        "for exp in range(NUM_EXPERIMENTS):\n",
        "    print('\\nExperiment %d #######################'%exp)\n",
        "    best_val_f, best_val_acc = 0, 0\n",
        "    best_val_r, best_val_p = 0, 0\n",
        "\n",
        "    last_batch = 0\n",
        "\n",
        "    model = RNN_all()\n",
        "    model = to_cuda(model)\n",
        "    optimizer = torch.optim.Adam(params=[p for p in model.parameters()],lr=0.001)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0\n",
        "        acc, dev_acc= 0 , 0\n",
        "        nepoch = epoch + 1\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "\n",
        "        for word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, y_hot_trn_bat, y_soft_trn_bat in train_loader:\n",
        "            hard_predictions, hard_loss = model(word_pad_trn_bat, word_iis_trn_bat, char_pad_trn_bat, y_hot_trn_bat, y_soft_trn_bat, False)\n",
        "            backprop_hot(optimizer, hard_loss)\n",
        "            running_loss += hard_loss.item()            \n",
        "\n",
        "            # as Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "            ps = torch.exp(hard_predictions)\n",
        "            top_p , top_class = ps.topk(1,dim=1)\n",
        "            equals = top_class == y_hot_trn_bat.view(*top_class.shape)\n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc+= torch.mean(equals.type(torch.FloatTensor))\n",
        "            \n",
        "        #monitioring the epoch time             \n",
        "        end_time = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "\n",
        "        #Traing Loss and Accuracy\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "        accs.append(acc/len(train_loader))\n",
        "        print(f'Training Loss: {train_losses[epoch]} | Training Acc: {accs[epoch].item()}')             \n",
        "\n",
        "        # evaluate after each epoch using \n",
        "        dev_hard_preds, dev_soft_preds = get_predictions(model, dev_loader)\n",
        "    \n",
        "        # # as Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "        # ps_d = torch.exp(torch.as_tensor(dev_soft_preds))\n",
        "        # top_pd , top_class_d = ps_d.topk(1,dim=1)\n",
        "        # equals_d = top_class_d == torch.as_tensor(dev_hard_preds).view(*top_class_d.shape)\n",
        "        # # Convert correct_counts to float and then compute the mean\n",
        "        # dev_acc += torch.mean(equals_d.type(torch.FloatTensor))\n",
        "        # dev_accs.append(dev_acc/ len(dev_loader))\n",
        "        # print('Dev Acc: ', dev_accs[epoch].item())\n",
        "        print('------------------------------------------------------------')\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Summary"
      ],
      "metadata": {
        "id": "g-NSzSxOBqir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsNMRYLAM0bg",
        "outputId": "ab1165df-01e9-435c-e30a-648985896103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN_all(\n",
            "  (word_encoder): Word_Encoder(\n",
            "    (bilstm): LSTM(300, 128, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (char_encoder): Char_Encoder(\n",
            "    (bilstm): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (char_attention): Attention(\n",
            "    (attn_nn): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (word_attention): Attention(\n",
            "    (attn_nn): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (fulcon): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=409, bias=True)\n",
            "    (1): Linear(in_features=409, out_features=327, bias=True)\n",
            "  )\n",
            "  (output_hot): Linear(in_features=327, out_features=12, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating model on Dev data**"
      ],
      "metadata": {
        "id": "lyAKIEsAB82F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"**Putting the data in the codalab answer format**\"\"\"\n",
        "#Gimpel-POS_answers.jsonlines- dev file\n",
        "\n",
        "codalab_dict = {str(i): {\"gold\": int(dev_hard_preds[i]), \"soft\": pred.tolist()} for i, pred in enumerate(dev_soft_preds)}\n",
        "codalab_dict = {\"dummy_name\": codalab_dict} \n",
        "\n",
        "with open(DATA_PATH +'/Gimpel-POS_answers-dev.jsonlines', 'w') as f:\n",
        "    json.dump(codalab_dict, f)"
      ],
      "metadata": {
        "id": "sGBVDBdvMLGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path of dev reference file\n",
        "dev_ref_path ='/content/drive/MyDrive/MscThesis/dev_reference_labels/Gimpel-POS_answers.jsonlines'\n",
        "# Path of dev result file\n",
        "dev_res_path= DATA_PATH+'/Gimpel-POS_answers-dev.jsonlines'\n",
        "\n",
        "num_classes = 12\n",
        "f1, recall, precision = get_hard_score(dev_ref_path, dev_res_path, num_classes)\n",
        "soft_score_dev = get_soft_score(dev_ref_path, dev_res_path)\n",
        "print('Dev Baseline Model')\n",
        "print(f'Precision:{precision*100 : .2f}% | Recall: {recall*100: .2f}% ')\n",
        "print(f'F1 scores: {f1} | Cross-Entropy: {soft_score_dev}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OAX6Qc4Ph7x",
        "outputId": "dd657cff-8aa8-492c-d4d7-adbc2992982f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev Baseline Model\n",
            "Precision: 78.65% | Recall:  78.49% \n",
            "F1 scores: 0.7713658644362331 | Cross-Entropy: 1.0867203501313014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating model on Test data**"
      ],
      "metadata": {
        "id": "uL2KLAYsCH_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data_path_test = '/content/drive/MyDrive/MscThesis/public_data_evaluation/gimpel_pos'"
      ],
      "metadata": {
        "id": "zi9bPkfKJbhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Importing Test Data\"\"\"\n",
        "# the test data from csv\n",
        "test_path = Data_path_test +'/test_data.tsv'\n",
        "test_data = read_csv_data(test_path)\n",
        "\n",
        "# the indices of the words in a sentence, saved as arrays. Hint:Helps you know where each sentence ends\n",
        "test_iis_path = Data_path_test +'/word_iis_tst.npy'\n",
        "word_iis_test = np.load(test_iis_path)\n",
        "\n",
        "# the padded sentences (maximum of 40 words per sentence). Two words in the same sentence will have the same word_pad. The numbers\n",
        "# indicate the idx of the word in the word embedding dictionary.\n",
        "test_wordpad_path = Data_path_test +'/word_pad_tst.npy'\n",
        "word_pad_test = np.load(test_wordpad_path)\n",
        "\n",
        "# the character padding\n",
        "test_charpad_path = Data_path_test + '/char_pad_tst.npy'\n",
        "char_pad_test = np.load(test_charpad_path)\n",
        "\n",
        "#\"\"\"**Getting, Tensorizing and Batching the Data**\"\"\"\n",
        "word_pad_tst_tens, word_iis_tst_tens, char_pad_tst_tens, hot_tst_tens, soft_tst_tens = create_dataset(word_pad_test, word_iis_test, char_pad_test)\n",
        "test = data_utils.TensorDataset(word_pad_tst_tens, word_iis_tst_tens, char_pad_tst_tens)\n",
        "test_loader = data_utils.DataLoader(test, batch_size=batsize, shuffle=False)\n"
      ],
      "metadata": {
        "id": "-QT1PnBwnj4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_hard_preds, test_soft_preds = get_predictions(model, test_loader)"
      ],
      "metadata": {
        "id": "feVifWjWYS5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BJshomSKXyn"
      },
      "outputs": [],
      "source": [
        "\"\"\"**Putting the data in the codalab answer format**\"\"\"\n",
        "#Gimpel-POS_answers.jsonlines- test file\n",
        "\n",
        "codalab_dict = {str(i): {\"gold\": int(test_hard_preds[i]), \"soft\": pred.tolist()} for i, pred in enumerate(test_soft_preds)}\n",
        "codalab_dict = {\"dummy_name\": codalab_dict} \n",
        "with open(DATA_PATH +'/Gimpel-POS_answers-test.jsonlines', 'w') as f:\n",
        "    json.dump(codalab_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path of test reference file\n",
        "test_ref_path= '/content/drive/MyDrive/MscThesis/test_reference_data/Gimpel-POS_answers.jsonlines'\n",
        "# Path of test result file\n",
        "test_res_path= '/content/drive/MyDrive/MscThesis/public_data_PP/gimpel_pos/Gimpel-POS_answers-test.jsonlines'\n",
        "\n",
        "num_classes = 12\n",
        "f1, recall, precision  = get_hard_score(test_ref_path, test_res_path, num_classes)\n",
        "soft_score = get_soft_score(test_ref_path, test_res_path)\n",
        "\n",
        "print('Test Baseline Model')\n",
        "print(f'Precision:{precision*100 : .2f}% | Recall: {recall*100: .2f}% ')\n",
        "print(f'F1 scores: {f1} | Cross-Entropy: {soft_score_dev}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-mYpJuDPdsM",
        "outputId": "acb868e9-ce29-4962-cbcb-2c29532cdf22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Baseline Model\n",
            "Precision: 78.10% | Recall:  77.92% \n",
            "F1 scores: 0.7688897758924997 | Cross-Entropy: 1.0867203501313014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## POS Tagging: NLTK and Spacy"
      ],
      "metadata": {
        "id": "xF9I5rIK7c7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating dev dataframe:**"
      ],
      "metadata": {
        "id": "KAcxO5sIdOfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df = pd.read_csv(DATA_PATH + '/input_data/dev_data.tsv', sep='\\t')\n",
        "dev_df['Hard_label'] = dev_hard_preds # storing dev hard lable\n",
        "dev_df['Soft_label'] = dev_soft_preds # storing dev soft lable\n",
        "dev_df['Hard_label_txt'] = ''\n",
        "dev_df['Sec_max_soft']= '' \n",
        "dev_df['Nltk_lable']= '' # for nltk tags \n",
        "dev_df['Spacy_lable']='' # for spacy tags"
      ],
      "metadata": {
        "id": "bMtLX4LVQ5BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cobqah_fLJmD",
        "outputId": "f013200e-17c9-45f9-faba-8e2cf2710904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3027, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting numerical lable to text lable\n",
        "for i in range(len(dev_df)):\n",
        "  dev_df['Hard_label_txt'].iloc[i] = list(labels_dict.keys())[int(dev_df['Hard_label'][i])]\n",
        "  #getting second maximun probabilty tag\n",
        "  slist = list(dev_df['Soft_label'][i]) \n",
        "  s_max_index = slist.index(sorted(slist)[-2])\n",
        "  dev_df['Sec_max_soft'].iloc[i] = list(labels_dict.keys())[int(s_max_index)]\n",
        "  "
      ],
      "metadata": {
        "id": "p5LNxZqzfTrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df.head(6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "9aS5fn2AMGiZ",
        "outputId": "f4479940-5681-4908-be0f-88e18dbea1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Twitt_ID  Token_Id_in_Dataset Token  Hard_label  \\\n",
              "0         0                    0    If           1   \n",
              "1         0                    1   you           7   \n",
              "2         0                    2   can          10   \n",
              "3         0                    3   see          10   \n",
              "4         0                    4  only           2   \n",
              "5         0                    5   one           6   \n",
              "\n",
              "                                          Soft_label Hard_label_txt  \\\n",
              "0  [0.016566958, 0.24222298, 0.057194225, 0.21483...            ADP   \n",
              "1  [0.0023907463, 0.0096095195, 0.007940512, 0.00...           PART   \n",
              "2  [0.0037132069, 0.008821263, 0.011603291, 0.008...           VERB   \n",
              "3  [0.01735294, 0.01964078, 0.032485157, 0.015387...           VERB   \n",
              "4  [0.14321233, 0.08693356, 0.34051514, 0.0649644...            ADV   \n",
              "5  [0.06372617, 0.05645435, 0.05653922, 0.0629671...            NUM   \n",
              "\n",
              "  Sec_max_soft Nltk_lable Spacy_lable  \n",
              "0        CCONJ                         \n",
              "1         VERB                         \n",
              "2         NOUN                         \n",
              "3          ADV                         \n",
              "4          ADJ                         \n",
              "5         NOUN                         "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe62923a-6fc2-4a9d-8f62-cbaa3487a81a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitt_ID</th>\n",
              "      <th>Token_Id_in_Dataset</th>\n",
              "      <th>Token</th>\n",
              "      <th>Hard_label</th>\n",
              "      <th>Soft_label</th>\n",
              "      <th>Hard_label_txt</th>\n",
              "      <th>Sec_max_soft</th>\n",
              "      <th>Nltk_lable</th>\n",
              "      <th>Spacy_lable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>If</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.016566958, 0.24222298, 0.057194225, 0.21483...</td>\n",
              "      <td>ADP</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>you</td>\n",
              "      <td>7</td>\n",
              "      <td>[0.0023907463, 0.0096095195, 0.007940512, 0.00...</td>\n",
              "      <td>PART</td>\n",
              "      <td>VERB</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>can</td>\n",
              "      <td>10</td>\n",
              "      <td>[0.0037132069, 0.008821263, 0.011603291, 0.008...</td>\n",
              "      <td>VERB</td>\n",
              "      <td>NOUN</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>see</td>\n",
              "      <td>10</td>\n",
              "      <td>[0.01735294, 0.01964078, 0.032485157, 0.015387...</td>\n",
              "      <td>VERB</td>\n",
              "      <td>ADV</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>only</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.14321233, 0.08693356, 0.34051514, 0.0649644...</td>\n",
              "      <td>ADV</td>\n",
              "      <td>ADJ</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>one</td>\n",
              "      <td>6</td>\n",
              "      <td>[0.06372617, 0.05645435, 0.05653922, 0.0629671...</td>\n",
              "      <td>NUM</td>\n",
              "      <td>NOUN</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe62923a-6fc2-4a9d-8f62-cbaa3487a81a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe62923a-6fc2-4a9d-8f62-cbaa3487a81a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe62923a-6fc2-4a9d-8f62-cbaa3487a81a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df['Hard_label_txt'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqDaToyDDfaf",
        "outputId": "2d48eab9-6a9a-4252-f90b-1686ef06e7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NOUN     907\n",
              "VERB     459\n",
              "PUNCT    435\n",
              "PART     335\n",
              "ADP      240\n",
              "ADJ      172\n",
              "X        125\n",
              "DET      103\n",
              "PRON     100\n",
              "ADV       89\n",
              "CCONJ     48\n",
              "NUM       14\n",
              "Name: Hard_label_txt, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning before tag generation**"
      ],
      "metadata": {
        "id": "2neljYAxdZCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {\"it's\":'it', \"theyre\":'they', 'fill-ups': 'fillup', \"I'm\": 'Iam', \"y'all\":'all',\"Y'all\":'all',\n",
        "       \"isn't\": 'is', 'X-mas':'xmas', 'How-To':'how', \"Don't\":'do', '!!!!!!':'!', \"what's\":'what',\n",
        "       \"that's\":'that', \"he's\":'he', \"that'd\":'that', \"you'll\":'you', \"can't\":'can', \"We'd\":'we', \n",
        "       \"He's\":'he', \"you're\":'you', '&hearts':'hearts','Wont': 'will', \"It's\":'is', 'im':'I', 'gonna':'going', 'cannot':'can', 'aint': 'are',\n",
        "       \"Ray-Ray\":'ray', \"Im\": 'Iam',\"That's\":'that',\"line-up\":'lineup', \"re-share\":'reshare','!?':'!','!!':'!','>>':'>', 'of_____________':'of',\n",
        "       \"id\":'ID', '<<-----':'<', '<==':'<','!!!':'!','!!!!!':'!', '-&':'-',\"Ricochet's\":'Ricochet', '??':'?', '...':'.','.....':'.','........':'.',\n",
        "       ']:':']', \"!'\":'!',\"=[[\":'=',\"\":'',\"didn't\":'did', \"Isn't\":'is',\"_)\":'_',\"[*\":'*',\n",
        "       \"gotta\":'go', \"whats\":'what', 't':'.', 'love':'love','*]':'*', '!!!!':'!', '!!!!!!!!':'!',\n",
        "        \")RT\":'RT', \"(@\":'(',\"Tracy's\":'Tracy','????':'?',\"I've\": 'I', \"she's\":'she', \"don't\":'do', \"won't\":'will',\"right-FREE\": 'FREE',\n",
        "       \"there's\":'there', \"I&\":'I','S/O':'so','<<':'<',\"KoryBaker262626\":'KoryBaker26262', \"D:\":':', \"Kalamazoo)\":'Kalamazoo',\n",
        "       \"((\":'(', '*))':'*', \"wasn't\":'was', \"We're\":'We',\"=>\":'=',\"!.\":'.',\n",
        "\n",
        "       }\n",
        "dev_df['Token'] = dev_df['Token'].replace(dic)\n"
      ],
      "metadata": {
        "id": "t8TYxNRDSdYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating NLTK Tags "
      ],
      "metadata": {
        "id": "GyvcDhd_8Iw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NLTK tagger\n",
        "nltk_tags= pos_tag(list(dev_df['Token']), tagset='universal')\n",
        "\n",
        "#saving tags in the dataframe\n",
        "for i in range(len(nltk_tags)):\n",
        "  dev_df['Nltk_lable'].iloc[i]= nltk_tags[i][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbWs6P7ntXnc",
        "outputId": "bbc53b99-b492-4e8b-f3a2-2ca6f252ab31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_block(indexer, value, name)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "svozMJPh8Y6F",
        "outputId": "ae0d26dd-e655-49c4-d252-cf5560337e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Twitt_ID  Token_Id_in_Dataset Token  Hard_label  \\\n",
              "0         0                    0    If           1   \n",
              "1         0                    1   you           7   \n",
              "2         0                    2   can          10   \n",
              "3         0                    3   see          10   \n",
              "4         0                    4  only           2   \n",
              "\n",
              "                                          Soft_label Hard_label_txt  \\\n",
              "0  [0.016566958, 0.24222298, 0.057194225, 0.21483...            ADP   \n",
              "1  [0.0023907463, 0.0096095195, 0.007940512, 0.00...           PART   \n",
              "2  [0.0037132069, 0.008821263, 0.011603291, 0.008...           VERB   \n",
              "3  [0.01735294, 0.01964078, 0.032485157, 0.015387...           VERB   \n",
              "4  [0.14321233, 0.08693356, 0.34051514, 0.0649644...            ADV   \n",
              "\n",
              "  Sec_max_soft Nltk_lable Spacy_lable  \n",
              "0        CCONJ        ADP              \n",
              "1         VERB       PRON              \n",
              "2         NOUN       VERB              \n",
              "3          ADV       VERB              \n",
              "4          ADJ        ADV              "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f914826-c5cd-41c5-8ae0-f60c99b7a7c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Twitt_ID</th>\n",
              "      <th>Token_Id_in_Dataset</th>\n",
              "      <th>Token</th>\n",
              "      <th>Hard_label</th>\n",
              "      <th>Soft_label</th>\n",
              "      <th>Hard_label_txt</th>\n",
              "      <th>Sec_max_soft</th>\n",
              "      <th>Nltk_lable</th>\n",
              "      <th>Spacy_lable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>If</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.016566958, 0.24222298, 0.057194225, 0.21483...</td>\n",
              "      <td>ADP</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>ADP</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>you</td>\n",
              "      <td>7</td>\n",
              "      <td>[0.0023907463, 0.0096095195, 0.007940512, 0.00...</td>\n",
              "      <td>PART</td>\n",
              "      <td>VERB</td>\n",
              "      <td>PRON</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>can</td>\n",
              "      <td>10</td>\n",
              "      <td>[0.0037132069, 0.008821263, 0.011603291, 0.008...</td>\n",
              "      <td>VERB</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>VERB</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>see</td>\n",
              "      <td>10</td>\n",
              "      <td>[0.01735294, 0.01964078, 0.032485157, 0.015387...</td>\n",
              "      <td>VERB</td>\n",
              "      <td>ADV</td>\n",
              "      <td>VERB</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>only</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.14321233, 0.08693356, 0.34051514, 0.0649644...</td>\n",
              "      <td>ADV</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>ADV</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f914826-c5cd-41c5-8ae0-f60c99b7a7c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f914826-c5cd-41c5-8ae0-f60c99b7a7c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f914826-c5cd-41c5-8ae0-f60c99b7a7c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NLTK Tag Count\n",
        "dev_df['Nltk_lable'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIL4vltkD8-3",
        "outputId": "ba738bfc-d9d9-444d-cd10-d2eaf5cac323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NOUN    1106\n",
              "VERB     452\n",
              ".        384\n",
              "PRON     243\n",
              "ADJ      206\n",
              "ADP      201\n",
              "DET      159\n",
              "ADV      134\n",
              "CONJ      58\n",
              "PRT       57\n",
              "NUM       20\n",
              "X          7\n",
              "Name: Nltk_lable, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating Spacy Tags"
      ],
      "metadata": {
        "id": "gpc_ROwF8RIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "#to remove # from the token\n",
        "for i in range(len(dev_df)):\n",
        "  dev_df['Token'][i] = re.sub('#', '', dev_df['Token'][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsOngFl_MkMZ",
        "outputId": "103f0efa-861f-4f28-b0a4-d37a0db864b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating text corpus\n",
        "txt = list(dev_df['Token'])\n",
        "txt = ' '.join(txt)\n",
        "\n",
        "#initializing spaCy object for toke generation\n",
        "text = sp(txt)\n",
        "text_token=[]\n",
        "for token in text:\n",
        "  text_token.append((token, token.pos_))\n",
        "\n",
        "#saving tags in the dataframe\n",
        "for i in range(len(dev_df)):\n",
        "  if dev_df['Token'][i] == str(text_token[i][0]):\n",
        "    dev_df['Spacy_lable'][i]= text_token[i][1]\n",
        "  else:\n",
        "    print(dev_df['Token'][i], str(text_token[i][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSJeONxn037b",
        "outputId": "96732032-b088-476c-d496-0ad104da6394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#spaCy Tag count\n",
        "dev_df['Spacy_lable'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfkaXX9UEEnj",
        "outputId": "1aeee0ad-c107-4429-ec35-39a8db10ccd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NOUN     602\n",
              "PUNCT    430\n",
              "PROPN    421\n",
              "VERB     341\n",
              "PRON     310\n",
              "ADP      198\n",
              "ADJ      138\n",
              "DET      137\n",
              "ADV      125\n",
              "AUX      112\n",
              "CCONJ     54\n",
              "SCONJ     41\n",
              "INTJ      40\n",
              "PART      32\n",
              "NUM       23\n",
              "X         18\n",
              "SPACE      2\n",
              "           2\n",
              "SYM        1\n",
              "Name: Spacy_lable, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving dataframe for Tag Comparison:"
      ],
      "metadata": {
        "id": "UwXinEmGdb31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#saving dataframe to excel\n",
        "dev_df.to_excel('/content/drive/MyDrive/MscThesis/dev.xlsx')"
      ],
      "metadata": {
        "id": "QNsAiwASh0Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model State "
      ],
      "metadata": {
        "id": "b_XgT5tmdmsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "metadata": {
        "id": "bfIWAjwJfu0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF0KbbrQfLdX",
        "outputId": "8610ca25-4d49-4558-b91e-4a99e8b336b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n",
            "word_encoder.bilstm.weight_ih_l0 \t torch.Size([512, 300])\n",
            "word_encoder.bilstm.weight_hh_l0 \t torch.Size([512, 128])\n",
            "word_encoder.bilstm.bias_ih_l0 \t torch.Size([512])\n",
            "word_encoder.bilstm.bias_hh_l0 \t torch.Size([512])\n",
            "word_encoder.bilstm.weight_ih_l0_reverse \t torch.Size([512, 300])\n",
            "word_encoder.bilstm.weight_hh_l0_reverse \t torch.Size([512, 128])\n",
            "word_encoder.bilstm.bias_ih_l0_reverse \t torch.Size([512])\n",
            "word_encoder.bilstm.bias_hh_l0_reverse \t torch.Size([512])\n",
            "char_encoder.bilstm.weight_ih_l0 \t torch.Size([512, 64])\n",
            "char_encoder.bilstm.weight_hh_l0 \t torch.Size([512, 128])\n",
            "char_encoder.bilstm.bias_ih_l0 \t torch.Size([512])\n",
            "char_encoder.bilstm.bias_hh_l0 \t torch.Size([512])\n",
            "char_encoder.bilstm.weight_ih_l0_reverse \t torch.Size([512, 64])\n",
            "char_encoder.bilstm.weight_hh_l0_reverse \t torch.Size([512, 128])\n",
            "char_encoder.bilstm.bias_ih_l0_reverse \t torch.Size([512])\n",
            "char_encoder.bilstm.bias_hh_l0_reverse \t torch.Size([512])\n",
            "char_attention.u_omega \t torch.Size([512])\n",
            "char_attention.attn_nn.0.weight \t torch.Size([512, 256])\n",
            "char_attention.attn_nn.0.bias \t torch.Size([512])\n",
            "word_attention.u_omega \t torch.Size([512])\n",
            "word_attention.attn_nn.0.weight \t torch.Size([512, 256])\n",
            "word_attention.attn_nn.0.bias \t torch.Size([512])\n",
            "fulcon.0.weight \t torch.Size([409, 512])\n",
            "fulcon.0.bias \t torch.Size([409])\n",
            "fulcon.1.weight \t torch.Size([327, 409])\n",
            "fulcon.1.bias \t torch.Size([327])\n",
            "output_hot.weight \t torch.Size([12, 327])\n",
            "output_hot.bias \t torch.Size([12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the model\n",
        "PATH='/content/drive/MyDrive/MscThesis/model.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "1SByprOafLZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading a saved model - Model class must be defined somewhere\n",
        "model = torch.load(PATH)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "AtaIyIbffLXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reference**"
      ],
      "metadata": {
        "id": "YROChIkYZp8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Pytorch.org. 2022. PyTorch documentation  PyTorch 1.12 documentation. [online] Available at: <https://pytorch.org/docs/stable/index.html> [Accessed 21 August 2022].\n",
        "\n",
        "*  Numpy.org. 2022. NumPy documentation  NumPy v1.23 Manual. [online] Available at: <https://numpy.org/doc/stable/> [Accessed 21 August 2022].\n",
        "\n",
        "*   Spacy.io. 2022. spaCy- Documentation. [online] Available at: <https://spacy.io/api> [Accessed 21 August 2022].\n",
        "\n",
        "*   Pytorch.org. 2022. GRU  PyTorch 1.12 documentation. [online] Available at: <https://pytorch.org/docs/stable/generated/torch.nn.GRU.html> [Accessed 21 August 2022].\n",
        "\n",
        "*  Pytorch.org. 2022. RNN  PyTorch 1.12 documentation. [online] Available at: <https://pytorch.org/docs/stable/generated/torch.nn.RNN.html> [Accessed 21 August 2022].\n",
        "\n",
        "*  Stack Overflow. 2022. Stack Overflow - Where Developers Learn, Share, & Build Careers. [online] Available at: <https://stackoverflow.com/> [Accessed 21 August 2022].\n"
      ],
      "metadata": {
        "id": "rWspImNkZvfV"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Main_POS_LSTM_Tanh()",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}